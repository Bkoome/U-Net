{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1CVGsWPKPKjOlpqYfGpR5xSCT26mMkjs-",
      "authorship_tag": "ABX9TyPSKYVYX9a0AO63RHkmnu3f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bkoome/U-Net/blob/main/Untitled23.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "bLVl-42qwvWL"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGESIZE = 256\n",
        "BATCHSIZE = 32\n",
        "EPOCHS = 50\n",
        "NUM_CLASSES = 3\n",
        "RGB_CHANNELS = 3"
      ],
      "metadata": {
        "id": "_VvJtzaN8mPs"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/Potato/VIAZI/Training',\n",
        "    shuffle=True,\n",
        "    image_size=(IMAGESIZE, IMAGESIZE),\n",
        "    batch_size=BATCHSIZE\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llgu6yoJ85jy",
        "outputId": "2d101526-862b-41e0-bcfe-757d4ce9eae3"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3261 files belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names=image_dataset.class_names\n",
        "class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmyfW1bV9Bsx",
        "outputId": "41ba8c71-3b30-4a31-f3f3-4ce69b537c86"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Early_Blight', 'Healthy', 'Late_Blight']"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset_partitions_tf(ds, train_split=0.8, validation_split=0.1, test_split=0.1, shuffle=True, shuffle_size=10000):\n",
        "  assert (train_split + validation_split + test_split)==1\n",
        "  ds_size=len(ds)\n",
        "  if shuffle:\n",
        "    ds=ds.shuffle(shuffle_size, seed=10)\n",
        "\n",
        "  train_size=int(train_split*ds_size)\n",
        "  validation_size=int(validation_split*ds_size)\n",
        "\n",
        "  train_dataset=ds.take(train_size)\n",
        "  validation_dataset=ds.take(validation_size)\n",
        "  test_dataset=ds.skip(train_size).skip(validation_size)\n",
        "\n",
        "  return train_dataset, validation_dataset, test_dataset"
      ],
      "metadata": {
        "id": "klbFhBQs9O_5"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, validation_dataset, test_dataset=get_dataset_partitions_tf(image_dataset)\n"
      ],
      "metadata": {
        "id": "RSvywj9O9cNF"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
        "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2)\n",
        "])\n",
        "\n",
        "train_dataset = train_dataset.map(\n",
        "    lambda x, y: (data_augmentation(x, training=True), y)\n",
        ").prefetch(buffer_size=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "l3D0Zc9u9hJk"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pu-DDXkA9fcy",
        "outputId": "e38f8bdb-3d13-4a5d-de60-629e56d9b0f2"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and compile the U-Net model\n",
        "def create_custom_unet(input_shape, num_classes):\n",
        "    inputs = keras.layers.Input(shape=input_shape)\n",
        "\n",
        "    # Encoder\n",
        "    conv1 = keras.layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
        "    conv1 = keras.layers.Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
        "    pool1 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = keras.layers.Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
        "    conv2 = keras.layers.Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
        "    pool2 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = keras.layers.Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
        "    conv3 = keras.layers.Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
        "    pool3 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "\n",
        "    # Decoder\n",
        "    up4 = keras.layers.Conv2DTranspose(128, 2, strides=(2, 2), padding='same')(conv3)\n",
        "    merge4 = keras.layers.concatenate([conv2, up4], axis=3)\n",
        "    conv4 = keras.layers.Conv2D(128, 3, activation='relu', padding='same')(merge4)\n",
        "\n",
        "    up5 = keras.layers.Conv2DTranspose(64, 2, strides=(2, 2), padding='same')(conv4)\n",
        "    merge5 = keras.layers.concatenate([conv1, up5], axis=3)\n",
        "    conv5 = keras.layers.Conv2D(64, 3, activation='relu', padding='same')(merge5)\n",
        "\n",
        "    outputs = keras.layers.Conv2D(num_classes, 1, activation='softmax')(conv5)\n",
        "\n",
        "    model = keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "metadata": {
        "id": "CPaf69xI-z-e"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_custom_unet((IMAGESIZE, IMAGESIZE, RGB_CHANNELS), NUM_CLASSES)"
      ],
      "metadata": {
        "id": "hVjtJp0o_Lgy"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "id": "Zn0h4Dgt_NqV"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset.element_spec)\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b79OAfxfEjbh",
        "outputId": "859f2039-a790-4183-912c-6c0852af4089"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)        [(None, 256, 256, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)          (None, 256, 256, 64)         1792      ['input_3[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)          (None, 256, 256, 64)         36928     ['conv2d_18[0][0]']           \n",
            "                                                                                                  \n",
            " max_pooling2d_6 (MaxPoolin  (None, 128, 128, 64)         0         ['conv2d_19[0][0]']           \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)          (None, 128, 128, 128)        73856     ['max_pooling2d_6[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)          (None, 128, 128, 128)        147584    ['conv2d_20[0][0]']           \n",
            "                                                                                                  \n",
            " max_pooling2d_7 (MaxPoolin  (None, 64, 64, 128)          0         ['conv2d_21[0][0]']           \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)          (None, 64, 64, 256)          295168    ['max_pooling2d_7[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)          (None, 64, 64, 256)          590080    ['conv2d_22[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_transpose_4 (Conv2D  (None, 128, 128, 128)        131200    ['conv2d_23[0][0]']           \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate  (None, 128, 128, 256)        0         ['conv2d_21[0][0]',           \n",
            " )                                                                   'conv2d_transpose_4[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)          (None, 128, 128, 128)        295040    ['concatenate_4[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_transpose_5 (Conv2D  (None, 256, 256, 64)         32832     ['conv2d_24[0][0]']           \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate  (None, 256, 256, 128)        0         ['conv2d_19[0][0]',           \n",
            " )                                                                   'conv2d_transpose_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)          (None, 256, 256, 64)         73792     ['concatenate_5[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)          (None, 256, 256, 3)          195       ['conv2d_25[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1678467 (6.40 MB)\n",
            "Trainable params: 1678467 (6.40 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fit_model = model.fit(\n",
        "    train_dataset,\n",
        "    batch_size=BATCHSIZE,\n",
        "    validation_data=validation_dataset,\n",
        "    verbose=1,\n",
        "    epochs=EPOCHS\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Beb9RE93GUoX",
        "outputId": "9a4517cc-8cc0-430f-91c9-9e21a65943df"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'fit_model = model.fit(\\n    train_dataset,\\n    batch_size=BATCHSIZE,\\n    validation_data=validation_dataset,\\n    verbose=1,\\n    epochs=EPOCHS\\n)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = model.evaluate(test_dataset)\n",
        "\n",
        "# Save the trained model\n",
        "model.save(\"/content/drive/MyDrive/Potato/segmentation_model\")"
      ],
      "metadata": {
        "id": "kA3W2h6f_W4l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}